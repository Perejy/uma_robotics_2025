{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed13281a-5914-477d-96d2-eac8e09e49da",
   "metadata": {},
   "source": [
    "# 6.3 Occupancy grid map building\n",
    "\n",
    "**Occupancy Grid Mapping (OGM)** is a fundamental technique in robotics for representing and understanding an environment in a structured way. It involves dividing the robot's environment into a **grid of cells**, where each cell contains a probability value representing whether it is occupied, free, or unknown. By incorporating sensor measurements over time, the robot can gradually build an accurate map of its surroundings. This **probabilistic approach** allows the robot to **handle uncertainties** in sensor data, which is crucial when dealing with real-world environments that are often dynamic and cluttered. Each sensor observation updates the occupancy probability of affected cells, enabling the robot to create a more accurate and reliable map over multiple measurements.\n",
    "\n",
    "OGM is especially relevant in modern robotics as it serves as the backbone for various tasks, such as navigation, localization, and path planning. Autonomous systems, from vacuum robots to self-driving cars, rely on occupancy grid maps to make informed decisions about movement and obstacle avoidance. By providing a representation of the environment that is continuously updated based on incoming data, OGM enables robots to operate autonomously and safely in complex, unpredictable spaces. This technique is critical in achieving reliable autonomy, as it provides a robust foundation for understanding the robot's surroundings and making intelligent decisions accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfb6e41-f888-40e5-93c2-f847e37255d9",
   "metadata": {},
   "source": [
    "## Notebook context: Autonomous Warehouse Robots\n",
    "\n",
    "In a warehouse setting, autonomous robots are often deployed to transport goods, organize inventory, or assist with order fulfillment. For these robots to perform their tasks efficiently and safely, they require an accurate map of the warehouse layout. Unlike highly dynamic environments, the layout of a warehouse remains relatively static over time, making an Occupancy Grid Map (OGM) an effective choice for mapping.\n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"images/amazon-proteus-warehouse-robot.jpg\" alt=\"\">\n",
    "  <figcaption>Amazon warehouse robot Proteus during its operation <a href=\"https://www.youtube.com/watch?v=AmmEbYkYfHY&t=103s&ab_channel=AmazonNews\" target=\"_blank\">(video)</a>.</figcaption>\n",
    "</figure>\n",
    "\n",
    "During the initial deployment phase, the robot can use its sensors to build an OGM of the warehouse. This map serves as a stable, long-term reference that the robot relies on for navigation and task planning. Since the OGM is probabilistic, it allows the robot to manage uncertainties in sensor data. Once the map is created, the robot can navigate accurately and avoid collisions, improving the efficiency of warehouse operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5610b599-e43e-4d7e-acbb-ff1e1e2410b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from laser.laser2D import Laser2D\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from utils.DrawRobot import DrawRobot\n",
    "from utils.tcomp import tcomp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc87636-e094-4a48-a774-dc6d11ef8c4a",
   "metadata": {},
   "source": [
    "## 6.3.1 Formalizing the problem\n",
    "\n",
    "When building a map using OGM, it is represented by  grid $m=\\{m_1,\\dots,m_k,\\dots,m_N\\}$, where each element of the map $m_k$ can be either occupied or empty. This way, each cell $m_k$ is modelled as a binary random variable that takes the value 1 for occupied space and 0 for empty. In the following image, occupied cells are represented with the black color, free cells with white, and uncertain space as gray (it is not clear if the cell is occupied or free).\n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"images/occupancy_grid_map_concept.jpg\" alt=\"\">\n",
    "</figure>\n",
    "\n",
    "Notice that the location of each cell $m_k$ is known, so the goal here is to compute their probability of being occupied by an obstacle, that is:\n",
    "\n",
    "$$\n",
    "P(m_k \\mid z_{1:t}, x_{1:t})\n",
    "$$\n",
    "\n",
    "being:\n",
    "\n",
    "- $z_{1:t}$ the observations captured by the robot from the beginning of its operation up to instant $t$.\n",
    "- $x_{1:t}$ the robot poses from where the observations were taken.\n",
    "\n",
    "Notice that a strong assumption is made: the probability of a cell being occupied is independent of each other. Typically the sensors used to build this kind of maps are scan-based ones, like sonars and 2D laser scanners. \n",
    "\n",
    "The probability of cell $m_i$ being occupied can be computed recursively:\n",
    "\n",
    "$$\n",
    "P(m_i | z_{1:t}, x_{1:t}) = \\frac{P(m_i | z_t, x_t) \\, p(z_t | x_t)}{P(m_i)} \\cdot \\frac{P(m_i | z_{1:t-1}, x_{1:t-1})}{p(z_t | z_{1:t-1}, x_{1:t})}\n",
    "$$\n",
    "\n",
    "Which can be retrieved more efficiently using **log odds**, that is, the natural logarithm of probability ratios:\n",
    "\n",
    "\n",
    "$$\\underbrace{\\ln \\frac{P(m_i|z_{1:t},x_{1:t})}{P(\\neg m_i|z_{1:t},x_{1:t}})}_{l_t(m_i)} = \n",
    "    \\underbrace{\\ln \\frac{P(m_i|z_t,x_t)}{P(\\neg m_i|z_t,x_t)}}_{\\tau_t(m_i)} + \n",
    "    \\underbrace{\\ln \\frac{P(m_i|z_{1:t-1},x_{1_:t-1})}{P(\\neg m_i|z_{1:t-1},x_{1_:t-1})}}_{l_{t-1}(m_i)} \n",
    "    \\underbrace{-\\ln \\frac{P(m_i)}{P(\\neg m_i)}}_{l_0(m_i)}\n",
    "$$\n",
    "\n",
    "\n",
    "Don't panic! We will analyze these expression with more detail in the upcoming sections.\n",
    "\n",
    "In the remaining of this notebook, we will cover:\n",
    "- the virtual map and the 2D laser scanner we are going to work with (section 6.3.2), and\n",
    "- the building of a OGM of said map (6.3.3), which involves the computation of occupancy probabilities by means of log odds. Let's go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a114d3c-6a50-421d-8e7a-0bee1be52b04",
   "metadata": {},
   "source": [
    "## 6.3.2 Understanding the environment and how the 2D laser works <span id=\"632\"></span>\n",
    "\n",
    "In this notebook we are going to simulate an environment as well as a 2D laser scanner able to take measurements from the robot to the obstacles in said environment (objects, assets like walls, doors, etc.). The following code cell defines that **virtual environment** into the **`virtual_map`** variable (one of the rock stars of this notebook), replicating a living-room with walls, a kitchen area, a sofa, a tv-cabinet and a table. The map is virtually representing the obstacles the laser may encounter during its operation **using lines**, that is, an horizontal cut of the environment at the laser height (assuming that the laser is placed in parallel with the floor).\n",
    "\n",
    "Execute it and analyze the shape of said map variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b563fee3-b6bf-4504-8ffe-133a7430bd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the environment\n",
    "map_type = 'living-room'\n",
    "    \n",
    "if map_type == 'living-room':\n",
    "    \n",
    "    walls = np.array([[2, 12, 12, 10, 10, 9.5, 9.5, 2, 2],\n",
    "                      [2, 2, 10, 10, 8, 8, 10, 10, 2]])\n",
    "\n",
    "    kitchen = np.array([[2, 8.5, 8.5, 9.5, 9.5, 2, 2, np.nan],\n",
    "                        [9, 9, 8, 8, 10, 10, 9, np.nan]])\n",
    "\n",
    "    sofa = np.array([[3.5, 7, 7, 3.5, 3.5, np.nan],\n",
    "                     [6, 6, 7, 7, 6, np.nan]])\n",
    "\n",
    "    tv_cabinet = np.array([[2.5, 7.5, 7.5, 2.5, 2.5, np.nan],\n",
    "                           [2, 2, 3, 3, 2, np.nan]])\n",
    "\n",
    "    table = np.array([[9.5, 11, 11, 9.5, 9.5, np.nan],\n",
    "                      [3.5, 3.5, 6, 6, 3.5, np.nan]])\n",
    "\n",
    "    \n",
    "    virtual_map = np.concatenate([walls, kitchen, sofa, tv_cabinet, table], axis=1)\n",
    "\n",
    "# Print map shape\n",
    "print('Map shape:', virtual_map.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5137a281-72e3-497a-8893-af3fbb9ea9dd",
   "metadata": {},
   "source": [
    "The `plot_virtual_map()` function is provided to help you visually interpret the process and understand what is happening. You don't need to understand its arguments now, they will be appearing throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55207e1-e5bf-411f-95ea-2ee091cd9fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_virtual_map(virtual_map, robot_pose=None, laser=None, z=None, z_world=None, cells_to_update=None):\n",
    "    \"\"\"\n",
    "    Plots the robot pose, virtual map, beam endpoints, and optionally grid cells to be updated.\n",
    "    \n",
    "    Parameters:\n",
    "    - virtual_map: environment representation using lines.\n",
    "    - robot_pose (optional): The position of the robot as a numpy array with shape (3, 1).\n",
    "    - laser (optional): Laser object.\n",
    "    - z (optional): Observation taken by the laser as a numpy array.\n",
    "    - z_world (optional): Array of beam endpoints in world coordinates.\n",
    "    - cells_to_update (optional): List of lists of grid cell coordinates to update.\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    # Plot the virtual map (environment boundaries or walls)\n",
    "    plt.plot(virtual_map[0, :], virtual_map[1, :], 'k-')    \n",
    "    \n",
    "    # Set grid and axis limits\n",
    "    plt.grid()\n",
    "    plt.xlim([np.nanmin(virtual_map[0])-2,np.nanmax(virtual_map[0])+2]) # nanmin ignores nan numbers\n",
    "    plt.ylim([np.nanmin(virtual_map[1])-2,np.nanmax(virtual_map[1])+2])  \n",
    "    \n",
    "    # Title and axis labels\n",
    "    plt.title('Living-room Map')\n",
    "    plt.xlabel('X position (m)')\n",
    "    plt.ylabel('Y position (m)')\n",
    "\n",
    "    if robot_pose is not None:\n",
    "        # Plot the robot position\n",
    "        DrawRobot(fig, ax, robot_pose, color='red')\n",
    "\n",
    "    if laser is not None and z is not None:\n",
    "        laser.draw_observation(z,laser_pose,fig,ax)\n",
    "    \n",
    "    if z_world is not None:\n",
    "        # Plot the beam endpoints in world coordinates\n",
    "        plt.plot(z_world[0], z_world[1], 'x')\n",
    "    \n",
    "    # If cells_to_update is provided, plot the grid cells to be updated\n",
    "    if cells_to_update is not None:\n",
    "        for cell_path in cells_to_update:\n",
    "            # Each cell_path is a list of (x, y) cell coordinates along one beam path\n",
    "            # Convert each cell's coordinates back to world coordinates using resolution\n",
    "            plt.plot([cell[0]*resolution for cell in cell_path], \n",
    "                     [cell[1]*resolution for cell in cell_path], \n",
    "                     's', markersize=5, color='blue', alpha=0.6, label='Cells to update')\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee168fa5-4762-4f0e-933b-472ff4e47209",
   "metadata": {},
   "source": [
    "Now visualize the map!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb18de8-0db2-4893-8cc8-e4181c7b69a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_virtual_map(virtual_map);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9929a62b-3772-45d9-9114-525811ff5c72",
   "metadata": {},
   "source": [
    "### The 2D laser scanner\n",
    "\n",
    "Okay, we have defined the environment, but to observe it we need some kind of sensor. In this case we are going to work with a 2D laser simulator. The following image illustrates the appearance of this kind of sensors.\n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "    <img src=\"images/sick_and_hokuyo_laser_scanners.png\" width=\"600px\" alt=\"\">\n",
    "    <figcaption>Top row, 2D laser scanners from <a href=\"https://www.sick.com/es/es/catalog/productos/safety/escaner-laser-de-seguridad/c/g569359\" href=\"_blank\">SICK</a>. Bottom row, left, 2D laser scanners from <a href=\"https://www.hokuyo-aut.jp/search/?cate01=1&cate02=1&cate03=\" target=\"_blank\">Hokuyo</a>, right, illustration of the field of view of some models of this brand.</figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "Concretely, the simulator is provided to you in the `Laser2D` class. The laser has a number of configuration parameters (properties) that can be set when creating an instance of it: \n",
    "\n",
    "- `FOV` -- Sensor field of view (radians)\n",
    "- `resolution` -- Sensor resolution (radians)\n",
    "- `max_distance` -- Max operating distance of the sensor (meters)\n",
    "- `noise_cov` -- covariance matrix characterizing sensor noise\n",
    "- `pose` -- sensor pose (column vector with x and y positions, and orientation theta)\n",
    "\n",
    "To keep it simple, we consider that the laser pose is the same of the robot one, that is, the laser is placed at the center of the robot and with the same orientation. \n",
    "\n",
    "The following code:\n",
    "\n",
    "- Initializes the robot pose and creates an instance of the `Laser2D` class. \n",
    "- Then, it takes an observation of the environment with the `take_observation()` method and, \n",
    "- to illustrate its operation, plots the resulting measurements with `draw_observation()`. \n",
    "\n",
    "Although not used in this example, there is also another interesting method, `set_pose`, that permits you to change the sensor pose according to the robot one. You can check the `Laser2D`code [here](./laser/laser2D.py).\n",
    "\n",
    "**Execute the cell** and pay special attention to the shape and contents of the observation `z`. *Hint: `z` is composed of a number of measurements, each representing the angle of an emitted laser beam and the distance to the closest object that the beam encounters.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e060987-5cb8-4783-bbad-fe15c7860bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set robot pose\n",
    "robot_pose = np.vstack([5, 4, np.pi/4]) # [x,y,theta]\n",
    "\n",
    "# Prepare the laser\n",
    "FOV = 180 * np.pi/180     # radians\n",
    "resolution = np.pi/180    #radians\n",
    "max_distance = 10         # meters\n",
    "noise_cov = np.array([[0.005, 0],[0, 0.0002]]) # covariance matrix\n",
    "laser_pose = robot_pose   # [x,y,theta]\n",
    "\n",
    "# Set a seed for random numbers\n",
    "np.random.seed(42)\n",
    "\n",
    "# Take and draw an observation!\n",
    "laser = Laser2D(FOV, resolution, max_distance, noise_cov, laser_pose)\n",
    "z = laser.take_observation(virtual_map)\n",
    "\n",
    "print('z shape',z.shape)\n",
    "print('z:',z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b374c382-34d1-482e-b351-54c25eb05db8",
   "metadata": {},
   "source": [
    "Now **visualize the virtual map and the observation** $z$ taken:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aee6f0c-9c0e-4682-8dcb-edb703254271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the map\n",
    "plot_virtual_map(virtual_map, robot_pose, laser=laser, z=z);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3a45fc-31c8-41e9-93b5-9fea5d72fddb",
   "metadata": {},
   "source": [
    "## 6.3.3 Building a map!\n",
    "\n",
    "Once presented the robot workspace and the 2D laser scanner the robot is equipped with, it is time to implement the occupancy grid mapping pipeline, which is as follows:\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> \n",
    "    \n",
    "  1. Initialize the grid map, log odds, and probabilities <b><i>(Assignment 1)</i></b>. \n",
    "  2. For each new observation $z_t$: <br>\n",
    "    - Do ray tracing to check which cells have been visited by each beam in the observation <b><i>(Assignments 2 and 3)</i></b>.  <br>\n",
    "    - Update cells' log odds of visited cells using beams and the inverse sensor model <b><i>(Assignments 4 and 5)</i></b>.\n",
    "  3. Once the robot stops collecting observations, compute final probabilities and retrieve the final map by applying an occupancy threshold <b><i>(Assignment 6)</i></b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab407d-c057-4359-92ad-e07f06c70584",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 1: Initializing the occupancy grid map</i></b></span>** \n",
    "\n",
    "The occupancy grid map itself has two properties:\n",
    "- Size (width and height, in meters)\n",
    "- Resolution (in meters): Size of the size of each cell in the map.\n",
    "\n",
    "This way, for example, if we model an environment of 10 by 10 meters with a grid resolution of 0.1 (cell side 0.1 meters), the resulting occupancy map will have a size of 100 by 100 cells. This map is stored in the `map` attribute of the `OccupancyGridMap` class (see below), and is computed in the last step of the building process.\n",
    "\n",
    "Recall that in order to obtain this map, we first have to combine all the observations coming from the sensor ($z_{1:t}$) and the poses from which they were taken ($x_{1:t}$) in order to retrieve the probability of each cell $m_k = m_{i,j}$ being occupied by an obstacle, that is $P(m_k| z_{1:t},x_{1:t})$, which will be stored in the `probabilities` attribute. This is done more efficiently working with log odds, as we will see later, so we will also keep the log odd of each cell in the `log_odds` attribute. \n",
    "\n",
    "**You are tasked to:**\n",
    "\n",
    "- Initialize the instance atribute `map` as a numpy array of ones with the right number of rows and columns as defined by the `width`, `height` and `resolution` parameters. \n",
    "- Initialize the `log_odds` attribute as a numpy array of zeros with the same size. They must be zeros since initially each cell has the same prior probability of being occupied than free, and that value represents 50% probability (we will see later on how log odds are converted into probabilities).\n",
    "- Initialize the instance atribute `probabilities` as a numpy array with values $0.5$ and the same size as the previous ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf03676f-7d38-4f65-aaf1-36ad903c753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OccupancyGridMap:\n",
    "    \n",
    "    def __init__(self, width, height, resolution):\n",
    "        \"\"\"Class constructor\n",
    "\n",
    "        Parameters:\n",
    "        width (int): Map width (in meters).\n",
    "        height (int): Map height (in meters).\n",
    "        resolution (float): Map resolution (in meters). For example if resolution=0.1 \n",
    "            this means that the side of each cell will be 10 centimiters.\n",
    "        \n",
    "       \"\"\"\n",
    "        self.width = None\n",
    "        self.height = None\n",
    "        self.resolution = None\n",
    "        \n",
    "        # Grid map initialization as a numpy array (notice that the height defines the \n",
    "        # number of rows, and the width the number of columns)\n",
    "        self.map = None\n",
    "        \n",
    "        # Log odds initialization (start with zero log-odds)\n",
    "        self.log_odds = None \n",
    "\n",
    "        # Probabilities initialization (start with 0.5)\n",
    "        self.probabilities = None\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade0bf2e-3025-44de-9b96-5a1fea5a5ec2",
   "metadata": {},
   "source": [
    "Cool! We're now ready to create an instance of this occupancy grid map. Create a map with these properties:\n",
    "\n",
    "- Width = 14m.\n",
    "- Height = 12m.\n",
    "- Resolution = 0.1m.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dd0f05-052f-4682-8c5b-a36e6a3b0ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map configuration\n",
    "map_width = None\n",
    "map_height = None\n",
    "resolution = None\n",
    "\n",
    "grid_map = OccupancyGridMap(None, None, None)\n",
    "\n",
    "print('grid_map.map shape:', grid_map.map.shape)\n",
    "print('grid_map.map content:\\n', grid_map.map)\n",
    "print('grid_map.log_odds content:\\n', grid_map.log_odds)\n",
    "print('grid_map.probabilities content:\\n', grid_map.probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1296c041-35ad-40c0-aa4a-29bd8bb53a58",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Expected output:</span>\n",
    "\n",
    "```\n",
    "grid_map.map shape: (120, 140)\n",
    "grid_map.map content:\n",
    " [[1. 1. 1. ... 1. 1. 1.]\n",
    " [1. 1. 1. ... 1. 1. 1.]\n",
    " [1. 1. 1. ... 1. 1. 1.]\n",
    " ...\n",
    " [1. 1. 1. ... 1. 1. 1.]\n",
    " [1. 1. 1. ... 1. 1. 1.]\n",
    " [1. 1. 1. ... 1. 1. 1.]]\n",
    "grid_map.log_odds content:\n",
    " [[0. 0. 0. ... 0. 0. 0.]\n",
    " [0. 0. 0. ... 0. 0. 0.]\n",
    " [0. 0. 0. ... 0. 0. 0.]\n",
    " ...\n",
    " [0. 0. 0. ... 0. 0. 0.]\n",
    " [0. 0. 0. ... 0. 0. 0.]\n",
    " [0. 0. 0. ... 0. 0. 0.]]\n",
    "grid_map.probabilities content:\n",
    " [[0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
    " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
    " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
    " ...\n",
    " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
    " [0.5 0.5 0.5 ... 0.5 0.5 0.5]\n",
    " [0.5 0.5 0.5 ... 0.5 0.5 0.5]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b3d592-97ca-4c3c-b56d-c41aa3cf2300",
   "metadata": {},
   "source": [
    "## Processing a new observation\n",
    "\n",
    "To build a map, while the robot is moving around, new observations are taken. For each new observation, we've to update the region of the map observed in it. In other words, given a measurement $z_t$, we have to process the sensor beams $z_t^i \\,, i\\in[0,\\dots,N\\_beams-1]$ in the following way.\n",
    "\n",
    "- a. Do ray tracing to check which cells have been visited by each beam in the observation.\n",
    "- b. Update cells' log odds of visited cells using beams and the inverse sensor model.\n",
    "\n",
    "### a. Ray tracing\n",
    "\n",
    "Ray tracing enables us to retrieve the cells the beam has visited until it hits an obstacle, to which we add some cells behind the obstacle. For doing that, we need:\n",
    "- The robot position.\n",
    "- The beam endpoint in world coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b89c70-5959-497a-978c-2e551e595a2e",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 2: Retrieving endpoints</i></b></span>** \n",
    "\n",
    "**Your task** is to complete the following `beams_endpoints()` method to compute the beams' endpoints in world coordinates for a given robot position $x_t=[x_t,y_t,\\theta_t]$ and an observation $z_t$. Concretely:\n",
    "\n",
    "- Calculate the angle $ \\theta^i = \\theta_t + \\phi^i $, where $ \\phi^i $ is the angle of the $ i $-th laser beam relative to the robot's orientation at time instant $t$.\n",
    "\n",
    "- Compute the endpoint $ (x_{\\text{end}}, y_{\\text{end}}) $:\n",
    "\n",
    "    $\n",
    "    x_{\\text{end}} = x_t + (\\rho_i + \\Delta \\rho )\\cos(\\theta_i),\n",
    "    $\n",
    "\n",
    "    $\n",
    "    y_{\\text{end}} = y_t + (\\rho_i + \\Delta \\rho )\\sin(\\theta_i),\n",
    "    $\n",
    "\n",
    "\n",
    "    where $ \\rho_i $ is the range measurement, and $\\Delta \\rho$ is an increment added to that range (`d_after_obstacle` in the code) to also update cells behind the obstacles up to that distance.\n",
    "\n",
    "Notice that in the codeit is checked if the obtained endpoints lay within the map limits `x_min`, `x_max`,`y_min`,`y_max`. If not, `\\Delta \\rho` is reduced and the new endpoint is computed. This is repeteted until a valid endpoint is obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934bc90b-832e-47b7-b149-6ecd65474130",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def beams_endpoints(robot_pose, z, grid_map, max_attempts=10, d_after_obstacle=1):\n",
    "    \"\"\"\n",
    "    Computes the endpoints of sensor beams in the world frame after extending beyond an obstacle,\n",
    "    adjusting endpoints that fall outside the grid_map boundaries by reducing d_after_obstacle.\n",
    "\n",
    "    Parameters:\n",
    "    - robot_pose: The position and orientation of the robot [x, y, theta]^T.\n",
    "    - z: Array of observations from the sensor (each element contains distance and angle).\n",
    "    - grid_map: The map containing width and height attributes that define boundaries.\n",
    "    - max_attempts: Maximum number of attempts to adjust each endpoint.\n",
    "    - d_after_obstacle: Initial extension distance in meters.\n",
    "\n",
    "    Returns:\n",
    "    - np.array: An array of adjusted endpoints in the world frame, with shape (2, n) for n beams.\n",
    "    \"\"\"\n",
    "    theta_robot = None\n",
    "    x_robot, y_robot = None, None\n",
    "    \n",
    "    # Map boundaries\n",
    "    x_min, x_max = 0, grid_map.width - 1*grid_map.resolution\n",
    "    y_min, y_max = 0, grid_map.height - 1*grid_map.resolution\n",
    "    \n",
    "    endpoints = []\n",
    "\n",
    "    # Iterate over each beam in z\n",
    "    for beam_distance, beam_angle in zip(z[0], z[1]):\n",
    "        theta_i = None\n",
    "        adjusted_d = d_after_obstacle  # Start with the initial d_after_obstacle for each beam\n",
    "\n",
    "        for _ in range(max_attempts+1):\n",
    "            # Calculate endpoint with the current adjusted_d\n",
    "            x = None\n",
    "            y = None\n",
    "\n",
    "            # Check if the endpoint is within map boundaries\n",
    "            if x_min <= x <= x_max and y_min <= y <= y_max:\n",
    "                endpoints.append([x, y])\n",
    "                break  # Found a valid endpoint, so exit the adjustment loop\n",
    "\n",
    "            # Reduce d_after_obstacle if out of bounds\n",
    "            adjusted_d -= d_after_obstacle/max_attempts \n",
    "\n",
    "        else: # Is executed only if the for is completed without a break (Corner case)\n",
    "            # If all attempts fail, use the robot's position as a fallback endpoint\n",
    "            endpoints.append([x_robot, y_robot])\n",
    "\n",
    "    return np.array(endpoints).T  # Return in shape (2, n)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfdcd13-038b-4c52-b5df-bdd12cd659ff",
   "metadata": {},
   "source": [
    "**Validate your implementation** with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad26b746-a3fe-4ade-989c-2edf356a27ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_robot_pose = np.vstack([5, 4, np.pi/4]) # [x,y,theta]\n",
    "toy_z = np.array([\n",
    "    [1.35469679, 2.31356178, 4.56578382, 4.47733733, 8.51936436, 2.4975578,\n",
    "     2.06864873, 1.93490656, 2.27144155, 4.30892947],\n",
    "    [-1.57868806, -1.23197124, -0.88225611, -0.53520384, -0.18372261, 0.16859342,\n",
    "     0.55460818, 0.90604182, 1.22760849, 1.6009752]\n",
    "    ])\n",
    "\n",
    "toy_z_endpoints = beams_endpoints(toy_robot_pose,\n",
    "                                  toy_z, \n",
    "                                  grid_map,\n",
    "                                  d_after_obstacle=1)  \n",
    "\n",
    "print('toy_z_endpoints.shape:',toy_z_endpoints.shape)\n",
    "print('toy_z_endpoints:\\n',toy_z_endpoints)\n",
    "\n",
    "plot_virtual_map(virtual_map, toy_robot_pose, z_world=toy_z_endpoints);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3821af3c-f3b5-478c-9d4c-19fe885cd7f5",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Expected output:</span>\n",
    "\n",
    "```\n",
    "toy_z_endpoints.shape: (2, 10)\n",
    "toy_z_endpoints:\n",
    " [[ 6.65183045  7.98860875 10.53969663 10.30679675 12.84765325  7.02309812\n",
    "   5.70194306  4.64678044  3.60002513  1.13445565]\n",
    " [ 2.32189001  2.56894814  3.46175212  5.3561462   9.38819416  6.85306582\n",
    "   6.98728656  6.91357383  6.95675501  7.63899697]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c55413-8179-4439-abb3-b95b9f4bd2e3",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 3: Doing ray tracing</i></b></span>** \n",
    "\n",
    "Once the starting (robot location) and endpoints are retrieved, they form lines that traverse a number of cells in the grid. But, which are there? **Ray tracing** comes to play to answer this question! Concretely, the next code cell provides a generator called `ray_tracing()` that returns the cells (their $x$ and $y$ coordinates) traversed by the line starting in $(x0,y0)$ and ending in $(x1,y1)$. It implements the **Bresenham's Line Algorithm** to determine the grid cells that are traversed, an efficient method for drawing a straight line between two points on a grid. Developed in 1962 by Jack Bresenham, the algorithm is widely used in computer graphics and robotics for its simplicity and speed, as it relies on integer arithmetic instead of floating-point calculations.\n",
    "\n",
    "The algorithm works by maintaining an error term that tracks the deviation from the ideal line. Depending on the slope, it primarily steps along either the $x-$ or $y-$axis, adjusting the other coordinate when the error exceeds a threshold. This results in a series of discrete points that closely follow the true line.\n",
    "\n",
    "**Implementation note: Generator function**\n",
    "\n",
    "A **generator** in Python is a special type of function that, instead of returning a single final value with a `return` statement, yields a sequence of values one at a time, using the `yield` keyword. This allows you to iterate over the values one by one without calculating or storing them all at once, which can be more memory-efficient and can allow for computations that continue until a certain condition is met. Interesting aspects:\n",
    "\n",
    "- When you call a generator for first time, it doesn't immediately return a result. Instead, it returns a generator object, which you can iterate over to retrieve values one at a time. Each iteration step calls the generator function and retrieves the next yielded value.\n",
    "- In a generator, `yield` pauses the function, saving its current state, and returns a value to the caller. When the generator is called again (by the next iteration, for example), it resumes from where it left off, with all its local variables and state intact.\n",
    "\n",
    "First, take a look at the `ray_tracing()`generator:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fce4e58-516b-4133-aa7a-8938a6b4d782",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ray_tracing(x0, y0, x1, y1):\n",
    "    \"\"\"\n",
    "    Bresenham's Line Algorithm in 2D.\n",
    "    Returns a generator of coordinate tuples along the line from (x0, y0) to (x1, y1).\n",
    "    \"\"\"\n",
    "\n",
    "    # Round coordinates to the nearest integers to work within a discrete grid\n",
    "    x0 = int(round(x0))\n",
    "    y0 = int(round(y0))\n",
    "    x1 = int(round(x1))\n",
    "    y1 = int(round(y1))\n",
    "    \n",
    "    # Calculate differences in x and y between the start and end points\n",
    "    dx = abs(x1 - x0)\n",
    "    dy = abs(y1 - y0)\n",
    "    \n",
    "    # Initialize starting point\n",
    "    x, y = x0, y0\n",
    "\n",
    "    # Determine the step direction in each axis (positive or negative)\n",
    "    sx = 1 if x1 >= x0 else -1  # Step in x direction\n",
    "    sy = 1 if y1 >= y0 else -1  # Step in y direction\n",
    "\n",
    "    # Check if the line is more horizontal or vertical by comparing dx and dy\n",
    "    if dy <= dx:\n",
    "        # If dx is greater, we will iterate primarily in the x direction\n",
    "        # Initialize error term to half of dx\n",
    "        err = dx / 2.0\n",
    "        while x != x1:  # Loop until we reach the end x-coordinate\n",
    "            yield x, y  # Yield the current point in the line\n",
    "            err -= dy  # Update error term by subtracting dy\n",
    "            if err < 0:  # If error goes negative, adjust the y-coordinate\n",
    "                y += sy  # Step in y direction\n",
    "                err += dx  # Update error term by adding dx\n",
    "            x += sx  # Step in x direction\n",
    "        yield x, y  # Yield the final point (x1, y1)\n",
    "    else:\n",
    "        # If dy is greater, we will iterate primarily in the y direction\n",
    "        # Initialize error term to half of dy\n",
    "        err = dy / 2.0\n",
    "        while y != y1:  # Loop until we reach the end y-coordinate\n",
    "            yield x, y  # Yield the current point in the line\n",
    "            err -= dx  # Update error term by subtracting dx\n",
    "            if err < 0:  # If error goes negative, adjust the x-coordinate\n",
    "                x += sx  # Step in x direction\n",
    "                err += dy  # Update error term by adding dy\n",
    "            y += sy  # Step in y direction\n",
    "        yield x, y  # Yield the final point (x1, y1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a3d4fe-7da2-4840-a565-6f9e8b06cd72",
   "metadata": {},
   "source": [
    "Now, **complete the following function** `gets_cells_to_upgrade()` that, given the robot pose, the beams' endpoints, and the map resolution, returns a list with the indices of the cells to be updated. For that:\n",
    "\n",
    "- This function first converts the robot's position and each beam endpoint from world coordinates to grid cell indices, based on the map resolution. For example, if the resolution is 0.5, and the robot pose is $[2,1,\\pi/4]^T$, then it will be placed at cell $(2/0.5,1/0.5)=(4,2)$.\n",
    "- It then uses Bresenham's line algorithm to trace each beam from the robot's cell to the corresponding beam endpoint cell. The cells along each traced beam path are added to a list, which is then returned as the final result.\n",
    "\n",
    "And how the `ray_tracing()` generator works here? In the ray_tracing function, `yield` is used to output each coordinate along the line one at a time:\n",
    "- When you use `list(ray_tracing(...))`, Python implicitly loops through the generator to gather each yielded value and store it in a list.\n",
    "- The first iteration of the loop calls the generator, which starts executing the `ray_tracing()` function from the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2de6f5-4bf9-498f-ad0f-49783f2def5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cells_to_update(robot_pose, z_endpoints, resolution, grid_shape):\n",
    "    \"\"\"\n",
    "    Determines which grid cells are intersected by sensor beams based on the robot's position, \n",
    "    beam endpoints, and map resolution. Only cells within the bounds of the grid map are returned.\n",
    "\n",
    "    Parameters:\n",
    "    - robot_pose (numpy array): The robot's pose in the environment as a column vector \n",
    "      with shape (3, 1), where robot_pose[0][0] is the x-coordinate and robot_pose[1][0] \n",
    "      is the y-coordinate.\n",
    "    - z_endpoints (numpy array): Array of shape (2, n), where each column represents the x and y\n",
    "      coordinates of the endpoint of a sensor beam, relative to the environment.\n",
    "    - resolution (float): The size of each grid cell, used to convert real-world coordinates \n",
    "      into grid cell indices.\n",
    "    - grid_shape (tuple): The shape of the grid map (height, width), used to validate cell indices.\n",
    "\n",
    "    Returns:\n",
    "    - cells_to_update (list): A list of lists, where each inner list contains the indices of \n",
    "      grid cells that each beam intersects and are within the grid boundaries.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize an empty list to store the cells to be updated for each beam\n",
    "    cells_to_update = []\n",
    "\n",
    "    # Convert the robot's position from world coordinates to grid cell indices\n",
    "    robot_cell_indices = [None, None]\n",
    "\n",
    "    # Iterate over each beam endpoint in z_endpoints\n",
    "    for beam_endpoint in z_endpoints.T:\n",
    "        # Convert the beam endpoint from world coordinates to grid cell indices\n",
    "        beam_endpoint_cell_indices = [None, None]\n",
    "\n",
    "        # Trace the line from the robot's cell to the beam endpoint cell, getting all cells along the path\n",
    "        cells_indices = list(ray_tracing(None, \n",
    "                                         None, \n",
    "                                         None, \n",
    "                                         None))\n",
    "\n",
    "        # Filter cells that are within the bounds of the grid map\n",
    "        valid_cells_indices = [\n",
    "            (int(x), int(y)) for x, y in cells_indices\n",
    "            if 0 <= int(x) < grid_shape[1] and 0 <= int(y) < grid_shape[0]\n",
    "        ]\n",
    "\n",
    "        # Append the list of valid cells for this beam path to the main list\n",
    "        cells_to_update.append(None)\n",
    "\n",
    "    # Return the list of cells that need to be updated and are within bounds\n",
    "    return cells_to_update\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc47a5b-c48e-43cf-af1c-5cf48bdbc992",
   "metadata": {},
   "source": [
    "And **validate it** with the following testing code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4935e7e6-715a-40b3-9a5e-632eba6b5259",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_cells_to_update = get_cells_to_update(toy_robot_pose, toy_z_endpoints, grid_map.resolution, grid_map.map.shape)\n",
    "\n",
    "# Just to get a visual intuition of what we're doing\n",
    "plot_virtual_map(virtual_map, toy_robot_pose, z_world=toy_z_endpoints, cells_to_update=toy_cells_to_update)\n",
    "\n",
    "# Print the number of lists and the length of each sublist in cells_to_update\n",
    "print(\"toy_cells_to_update shape:\", len(toy_cells_to_update), \"x\", [len(sublist) for sublist in toy_cells_to_update])\n",
    "print('toy_cells_to_update (just first two beams):',toy_cells_to_update[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f288cb2a-8925-4c67-9614-bbf141a72fa5",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Expected output:</span>\n",
    "\n",
    "```\n",
    "toy_cells_to_update shape: 10 x [18, 30, 56, 54, 79, 29, 30, 30, 30, 40]\n",
    "toy_cells_to_update (just first two beams): [[(50, 40), (51, 39), (52, 38), (53, 37), (54, 36), (55, 35), (56, 34), (57, 33), (58, 32), (58, 31), (59, 30), (60, 29), (61, 28), (62, 27), (63, 26), (64, 25), (65, 24), (66, 23)], [(50, 40), (51, 39), (52, 39), (53, 38), (54, 38), (55, 37), (56, 37), (57, 36), (58, 36), (59, 35), (60, 35), (61, 34), (62, 34), (63, 33), (64, 33), (65, 32), (66, 32), (67, 31), (68, 31), (69, 30), (70, 30), (71, 29), (72, 29), (73, 28), (74, 28), (75, 27), (76, 27), (77, 26), (78, 26), (79, 25)]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac2dbe5-ac55-4280-9880-5e3f75555129",
   "metadata": {
    "tags": []
   },
   "source": [
    "### b. Log odds update\n",
    "\n",
    "Cool! Each time a new observation $z_t$ comes, we're able to retrieve the observed space in terms of traversed cells. Now, to introduce the information provided by the observation, we should update the probability of cells being occupied according to it. However, to do it more effectively, we will rely on the following recursive expression for updating the **log odd values** of traversed cells:\n",
    "\n",
    "$$\\underbrace{\\ln \\frac{P(m_i|z_{1:t},x_{1:t})}{P(\\neg m_i|z_{1:t},x_{1:t}})}_{l_t(m_i)} = \n",
    "    \\underbrace{\\ln \\frac{P(m_i|z_t,x_t)}{P(\\neg m_i|z_t,x_t)}}_{\\tau_t(m_i)} + \n",
    "    \\underbrace{\\ln \\frac{P(m_i|z_{1:t-1},x_{1_:t-1})}{P(\\neg m_i|z_{1:t-1},x_{1_:t-1})}}_{l_{t-1}(m_i)} \n",
    "    \\underbrace{-\\ln \\frac{P(m_i)}{P(\\neg m_i)}}_{l_0(m_i)}$$\n",
    "\n",
    "Expressed more conveniently as:\n",
    "\n",
    "$$l_t(m_i)=\\tau_t(m_i)+l_{t-1}(m_i)+l_0(m_i)$$\n",
    "\n",
    "Let's know a little more the terms of this expression:\n",
    "\n",
    "- $l_0(m_i)$: represents the **initial log-odd** of occupancy for a grid cell $m_i$ at the beginning of the map building process (before any sensor measurements are processed). It encodes the prior probability of the cell being occupied. For instance, if we start with the assumption that all cells are equally likely to be occupied or unoccupied (an occupancy probability of 0.5, so $P(m_i)=0.5$ and $P(\\neg m_i)=0.5)$), then $l_0(m_i)=0$ since $ln(0.5/0.5)=0$. This is a constant value, calculated just once, at the beginning. \n",
    "- $l_{t-1}(m_i)$: is called the **prior log-odd**, the previous log-odd, serving as the recursive component of this equation.\n",
    "- $\\tau_t(m_i)$: represents the **sensor model in log-odds form** for the current measurement $z_t$ and robot pose $x_t$. It describes how the sensor reading affects the occupancy probability of the cell $m_i$ at current time step $t$. It represents the ratio of the probability that the cell is occupied given the current measurement, to the probability that it is not occupied given the same measurement.\n",
    "\n",
    "This way, the only term that must be computed at each time instant $t$ is the $\\tau_t(m_i)$, which is then added to the prior log-odd $l_{t-1}(m_i)$ and the initial log odd $l_0(m_i)$. Recall that this term is computed as:\n",
    "\n",
    "$$\n",
    "\\tau_t(m_i) = \\ln \\frac{P(m_i|z_t,x_t)}{P(\\neg m_i|z_t,x_t)}\n",
    "$$\n",
    "\n",
    "In other words, we need to employ the inverse sensor model to retrieve the probability $P(m_i|z_t,x_t)$. For efficiency, this must be done only for the observed cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7588318-05b2-4e96-b941-d75ae01188c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### The inverse sensor model\n",
    "\n",
    "The **inverse sensor model** is based on the computation of the following function, representing a Gaussian probability distribution:\n",
    "\n",
    "$$\n",
    "f(d) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\frac{1}{2} \\frac{(d - z_t)^2}{\\sigma^2}}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $z_t$ is the observed distance to an object detected by the sensor.\n",
    "- $\\sigma$ is the standard deviation, as provided by the laser manufacturer or obtained experimentally.\n",
    "- $d=d(x_t,m_i)$ is the distance from the laser position at instant $t$ (here, the same as the laser position $x_t$) to the cell $m_i$.\n",
    "\n",
    "Concretely, this function is used to define the occupancy probability for cells at varying distances $d$ along the beam path as:\n",
    "\n",
    "$$\n",
    "P(m_i | z_t, x_t) = \n",
    "\\begin{cases} \n",
    "l_{\\text{th}} & \\text{if } d < z_t \\text{ and } f(d) < l_{\\text{th}} \\\\ \n",
    "0.5 & \\text{if } d > z_t \\text{ and } f(d) < 0.5 \\\\ \n",
    "f(d) & \\text{Otherwise} \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "The following image visually illustrates the meaning of this definition, as well as how it is used to retrieve log odds (to be explained in the next assignment).\n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"images/inverse_sensor_model.jpg\" alt=\"\">\n",
    "</figure>\n",
    "\n",
    "Notice that this approach avoids setting probabilities to exactly 0 or 1 to account for uncertainties like sensor noise and improve numerical stability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3fa2ac-2f95-4615-8fab-48ddfeb03bc7",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 4: Implementing the inverse sensor model</i></b></span>** \n",
    "\n",
    "**Your task is** to complete the following `inverse_beam_sensor_model` that, given:\n",
    "- the robot pose (`robot_pose`),\n",
    "- an observation (`z`), and\n",
    "- a list of cells to be updated (`cells_to_update`),\n",
    "\n",
    "returns a list of the same shape (`p_cell_occupied`) with the probabilities of those cells being occupied. Some considerations:\n",
    "\n",
    "- Set the lower probability threshold $l_{th}$ to $0.2$.\n",
    "- Set `sigma`, the sensor uncertainty, as `0.4`.\n",
    "- If the value computed by `f` is larger than $0.8$, saturate it to that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247fbd73-2761-42b9-b09f-83e3ee7269a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_beam_sensor_model(robot_pose, z, cells_to_update, resolution):\n",
    "    \"\"\"\n",
    "    Computes the occupancy probabilities for cells traversed by each beam \n",
    "    in a laser observation, based on an inverse sensor model. \n",
    "\n",
    "    Parameters:   \n",
    "    - robot_pose: np.array\n",
    "        The pose of the robot as a 2D array, where the first row contains \n",
    "        the x-coordinate and the second row contains the y-coordinate of \n",
    "        the robot.\n",
    "    - z: np.array\n",
    "        A 2D array with the observation taken.\n",
    "    - cells_to_update: list of lists\n",
    "        A list where each element is a list of (i, j) cell indices that \n",
    "        correspond to the cells visited by a specific beam.\n",
    "     - resoultion: resolution of the grid map being built\n",
    "\n",
    "    Returns:\n",
    "    - p_cell_occupied: list of lists\n",
    "        A list with the same structure as `cells_to_update`, containing \n",
    "        the computed occupancy probabilities for each cell along each beam.\n",
    "    \"\"\"\n",
    "    \n",
    "    sigma = None # Standard deviation modeling sensor uncertainty       \n",
    "    l_th = None  # Lower probability threshold\n",
    "    \n",
    "    # Define robot position in terms of cells\n",
    "    x = None\n",
    "    y = None\n",
    "    \n",
    "    # Number of beams in the observation\n",
    "    n_beams = z.shape[1]\n",
    "\n",
    "    # Initialize output list to store occupancy probabilities for each beam\n",
    "    p_cell_occupied = [[] for _ in range(n_beams)]\n",
    "    \n",
    "    # Process each beam observation\n",
    "    for beam_index in np.arange(n_beams):\n",
    "        \n",
    "        # The measured distance for the current beam in terms of cells\n",
    "        z_i = None\n",
    "\n",
    "        # Calculate occupancy probability for each cell traversed by the beam\n",
    "        for cell in cells_to_update[beam_index]:\n",
    "            \n",
    "            # Compute Euclidean distance between the robot and the cell\n",
    "            d = None\n",
    "            \n",
    "            # Compute the value for the gaussian probability distribution\n",
    "            f = None            \n",
    "\n",
    "            # Determine final occupancy probability based on conditions\n",
    "            if None:\n",
    "                p_cell_occupied[beam_index].append(l_th)\n",
    "            elif None:\n",
    "                p_cell_occupied[beam_index].append(0.5)\n",
    "            else:\n",
    "                if None:\n",
    "                    f = None\n",
    "                p_cell_occupied[beam_index].append(f)\n",
    "\n",
    "                    \n",
    "    return p_cell_occupied\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf484fc-cdef-4b2e-8c4c-d63fa8e772b7",
   "metadata": {},
   "source": [
    "**Check** that your implementation is right:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be5662a-e753-48f4-8292-513de2639be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_p_cells_occupied = inverse_beam_sensor_model(toy_robot_pose, \n",
    "                                                toy_z, \n",
    "                                                toy_cells_to_update,\n",
    "                                                grid_map.resolution)\n",
    "\n",
    "print('toy_p_cells_occupied (just two first beams):\\n',toy_p_cells_occupied[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a083eb5-a380-474f-bd1f-9f5b99377204",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Expected output:</span>\n",
    "\n",
    "```\n",
    "toy_p_cells_occupied (just two first beams):\n",
    " [[0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.8, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5], [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cd71e4-ac36-4d33-9433-e01375e6c519",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 5: Updating log odds and probabilities</i></b></span>** \n",
    "\n",
    "And the time has come for updating the log odds! As commented, for efficiency, this is just done for the cells traversed by any beam. **Complete the following cell** to do two things:\n",
    "\n",
    "- First, compute initial log odds $l_0$ for all the cells, taking into account that the prior probability of a cell being occupied is 0.5 ($P(m_i)=0.5$).\n",
    "- Then, define the `update_log_odds()` function that given:\n",
    "  - the map to be updated (`grid_map`),\n",
    "  - the cells to be updated (`p_cells_occupied`),\n",
    "  - the probability of said cells according to the inverse sensor model (`p_cells_occupied`),\n",
    "  - and the mentioned initial log odd $l_0$,\n",
    "\n",
    "  updates the log_odds of cells traversed by any beam.\n",
    "\n",
    "  **Important note:** take into account that when indexing a matrix using `[row][col]`, `x` coordinates refers to columns and `y` coordinates to rows!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e7fcb9-86ab-4169-beed-7846828e165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_occupied = None\n",
    "p_free = None\n",
    "l_0 = -np.log(None)\n",
    "\n",
    "def update_log_odds(grid_map, cells_to_update, p_cells_occupied, l_0):\n",
    "    \"\"\"\n",
    "    Updates the log-odds values of cells in the occupancy grid map based on new sensor observations.\n",
    "\n",
    "    Parameters:\n",
    "    - grid_map: object\n",
    "        The occupancy grid map object that has an attribute `log_odds`, a 2D array representing\n",
    "        the log-odds values of occupancy for each cell in the map.\n",
    "    - cells_to_update: list of lists\n",
    "        A list where each element is a list of (i, j) tuples representing the indices of cells \n",
    "        traversed by a specific beam. Each sublist corresponds to one beam in the observation.\n",
    "    - p_cells_occupied: list of lists\n",
    "        A list of lists containing the occupancy probabilities for each cell in each beam path.\n",
    "        The structure matches `cells_to_update`, where each sublist corresponds to one beam.\n",
    "    - l_0: float\n",
    "        The prior log-odds value used to initialize cells. This value is added to each cell's \n",
    "        log-odds during updates to incorporate prior knowledge.\n",
    "\n",
    "    This function updates `grid_map.log_odds` in-place, incorporating the latest observation data \n",
    "    and progressively refining the map’s understanding of which cells are likely occupied or free.\n",
    "    \"\"\"\n",
    "\n",
    "    # Iterate over observation beams\n",
    "    for beam_index in range(len(cells_to_update)):\n",
    "        \n",
    "        # Iterate over the cells traversed by this beam\n",
    "        for traversed_cell, p_occupied in zip(cells_to_update[beam_index], p_cells_occupied[beam_index]):\n",
    "\n",
    "            # Compute the sensor model log odd\n",
    "            tau_t = None\n",
    "\n",
    "            # Update cell log odds!\n",
    "            grid_map.log_odds[None][None] += None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae8a0b1-1dd5-458f-8713-59c1e3390132",
   "metadata": {},
   "source": [
    "**Test your implementation**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eddfa0f-eb97-4d1e-9c2e-a0a65af5682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_log_odds(grid_map,\n",
    "                toy_cells_to_update, \n",
    "                toy_p_cells_occupied, \n",
    "                l_0)\n",
    "\n",
    "print('log_odds (just for a portion of the map):\\n',grid_map.log_odds[55:60,40:45])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2fe28e-0eb2-45b3-8517-efc44154df38",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Expected output **JUST AFTER THE FIRST EXECUTION!** If you execute the cell more than one time, you are simulating multiple observations from the same pose:</span>\n",
    "\n",
    "```\n",
    "log_odds (just for a portion of the map):\n",
    " [[ 0.          0.          0.         -1.38629436  0.        ]\n",
    " [ 0.          0.         -1.38629436  0.          0.        ]\n",
    " [ 0.          0.         -1.38629436  0.          0.        ]\n",
    " [ 0.         -1.38629436  0.          0.          0.        ]\n",
    " [ 0.         -1.38629436  0.          0.          0.        ]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58897d0-b84a-4920-9ca3-4f9efa1dd9bb",
   "metadata": {},
   "source": [
    "Once we have updated the log odds, we can retrieve the probability of each cell being occupied. This is done just once, when the robot has completed the environment exploration, but we will define a function to do it in each iteration just to visualize how probabilities evolve.\n",
    "\n",
    "**You are tasked to** complete the `update_probabilities()` function that, according to log odd values (stored in `grid_map.log_odds`) updates cells' probabilities (stored in `grid_map.probabilities`) using the following expression:\n",
    "\n",
    "$$\n",
    "P(m_i | z_{1:t}, x_{1:t}) = \\frac{e^{l_t(m_i)}}{1 + e^{l_t(m_i)}} = 1 - \\frac{1}{1 + e^{l_t(m_i)}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7492f4-eff7-4f6e-ad4f-805af5acb02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_probabilities(grid_map):\n",
    "    \"\"\"\n",
    "    Updates the occupancy probabilities in the grid map based on the current log-odds values.\n",
    "\n",
    "    This function converts log-odds values stored in `grid_map.log_odds` to occupancy probabilities \n",
    "    and stores the result in `grid_map.probabilities`. It uses the sigmoid function to map log-odds \n",
    "    to probability values, where each cell's probability represents the likelihood of being occupied.\n",
    "\n",
    "    Parameters:\n",
    "    - grid_map: An object containing:\n",
    "        - log_odds: A 2D numpy array with log-odds values for each cell in the occupancy grid.\n",
    "        - probabilities: A 2D numpy array that will be updated with the computed occupancy probabilities.\n",
    "\n",
    "    Note:\n",
    "    This function modifies `grid_map.probabilities` in place.\n",
    "    \"\"\"\n",
    "    grid_map.probabilities = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ff2cbf-f2bf-44df-9dba-42aea2362563",
   "metadata": {},
   "source": [
    "### Putting all together\n",
    "\n",
    "Until now we have implemented the needed building blocks to, given a new observation $z$, process it and update the log odds an probabilities of a map. Now it's time to put all together!\n",
    "\n",
    "Before that, take a look at the following function, `plot_state()`, which shows the virtual map, the robot pose, beams' endpoints, and the map probabilities after processing an observation. It is also provided the `create_and_display_buttons()` function, that will permit you to move the robot in the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c888f9c-8b07-46c4-82e7-af61201bb92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_state(robot_pose, z_world, virtual_map, grid_map, cells_to_update=None):\n",
    "    \"\"\"\n",
    "    Plots the robot pose, map, beam endpoints, and optionally grid cells to be updated\n",
    "    alongside the occupancy grid map.\n",
    "\n",
    "    Parameters:\n",
    "    - robot_pose: The position of the robot as a numpy array or list with shape (2, 1).\n",
    "    - z_world: Array of beam endpoints in world coordinates.\n",
    "    - virtual_map: The map to be plotted (e.g., walls or environment boundaries).\n",
    "    - grid_map: Object containing occupancy probabilities for each cell in the grid.\n",
    "    - cells_to_update (optional): List of lists of grid cell coordinates to update.\n",
    "    - resolution: Resolution for converting cell coordinates to world coordinates (default is 1).\n",
    "    \"\"\"\n",
    "    with output:  # Direct output to the Output widget\n",
    "        clear_output(wait=True)\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "        # Plot the virtual map (environment boundaries or walls) in the first subplot\n",
    "        ax1.plot(virtual_map[0, :], virtual_map[1, :], 'k-')\n",
    "        \n",
    "        # Set grid and axis limits\n",
    "        ax1.grid()\n",
    "        ax1.set_xlim(np.nanmin(virtual_map[0])-2,np.nanmax(virtual_map[0])+2) # nanmin ignores nan numbers\n",
    "        ax1.set_ylim(np.nanmin(virtual_map[1])-2,np.nanmax(virtual_map[1])+2)  \n",
    "        \n",
    "        # Title and axis labels\n",
    "        ax1.set_title('Living-room Map')\n",
    "        ax1.set_xlabel('X position (m)')\n",
    "        ax1.set_ylabel('Y position (m)')   \n",
    "                \n",
    "        # Plot the beam endpoints in world coordinates\n",
    "        ax1.plot(z_world[0], z_world[1], 'x')\n",
    "        \n",
    "        # If cells_to_update is provided, plot the grid cells to be updated\n",
    "        if cells_to_update is not None:\n",
    "            for cell_path in cells_to_update:\n",
    "                ax1.plot([cell[0] * grid_map.resolution for cell in cell_path], \n",
    "                         [cell[1] * grid_map.resolution for cell in cell_path], \n",
    "                         's', markersize=5, color='blue', alpha=0.2)\n",
    "\n",
    "            \n",
    "        # Draw robot (the usual DrawRobot function doesn't work because of the subplots) \n",
    "        ax1.plot(robot_pose[0, 0], robot_pose[1, 0], 'o', color='red', markersize=10, alpha=0.6)\n",
    "        orientation_length = 0.5  # Length of the orientation line\n",
    "        x_start, y_start = robot_pose[0, 0], robot_pose[1, 0]\n",
    "        x_end = x_start + orientation_length * np.cos(robot_pose[2, 0])\n",
    "        y_end = y_start + orientation_length * np.sin(robot_pose[2, 0])\n",
    "        ax1.plot([x_start, x_end], [y_start, y_end], color='red', linewidth=2, alpha=0.7)\n",
    "\n",
    "        # Plot the occupancy grid map with probabilities in the second subplot\n",
    "        cax = ax2.imshow(grid_map.probabilities, cmap='gray_r', origin='lower', vmin=0, vmax=1)\n",
    "        ax2.set_title('Occupancy Grid Map')\n",
    "        ax2.set_xlabel('X (cells)')\n",
    "        ax2.set_ylabel('Y (cells)')\n",
    "        fig.colorbar(cax, ax=ax2, label='Occupancy Probability')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close(fig)  # Ensure the figure is closed after display to avoid lingering\n",
    "\n",
    "def create_and_display_buttons():\n",
    "\n",
    "    translation_step = 0.5\n",
    "    rotation_step = np.pi/4\n",
    "    \n",
    "    def on_button_up_click(b):\n",
    "        move_robot(dx=translation_step)\n",
    "    \n",
    "    def on_button_down_click(b):\n",
    "        move_robot(dx=-translation_step)\n",
    "    \n",
    "    def on_button_left_click(b):\n",
    "        None\n",
    "    \n",
    "    def on_button_right_click(b):\n",
    "        None\n",
    "    \n",
    "    def on_button_rotate_left_click(b):\n",
    "        move_robot(dtheta=rotation_step)\n",
    "    \n",
    "    def on_button_rotate_right_click(b):\n",
    "        move_robot(dtheta=-rotation_step)\n",
    "    \n",
    "    button_up = widgets.Button(description=\"↑\")\n",
    "    button_down = widgets.Button(description=\"↓\")\n",
    "    button_left = widgets.Button(description=\" \")\n",
    "    button_right = widgets.Button(description=\" \")\n",
    "    button_rotate_left = widgets.Button(description=\"↺\")\n",
    "    button_rotate_right = widgets.Button(description=\"↻\")\n",
    "    \n",
    "    button_up.on_click(on_button_up_click)\n",
    "    button_down.on_click(on_button_down_click)\n",
    "    button_left.on_click(on_button_left_click)\n",
    "    button_right.on_click(on_button_right_click)\n",
    "    button_rotate_left.on_click(on_button_rotate_left_click)\n",
    "    button_rotate_right.on_click(on_button_rotate_right_click)\n",
    "    \n",
    "    control_box = widgets.HBox([button_rotate_left, button_up, button_rotate_right])\n",
    "    control_box2 = widgets.HBox([button_left, button_down, button_right])\n",
    "    display(control_box, control_box2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d195def8-f812-476f-bdbf-a2eba98117a4",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 6: Combining All Parts</i></b></span>** \n",
    "\n",
    "It's the moment to put all our machinery to work. For that, **you have to complete** the `process_new_observation()` function that, given a `grid_map`, a `robot_pose`, and an observation `z`, process said observation and update log odds and probabilities.\n",
    "\n",
    "There is also a second function to be completed, called `move_robot()`, which receives as argument a pose increment, and moves the robot by composing its pose with said increment using our loved `tcomp()` function. After that, it sets the laser pose accordingly, takes a new measurement, and calls `process_new_observation()`. This is the function that will be called each time a button to move the robot is pressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7664932f-b5fc-4376-ae05-e5df10715a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_new_observation(grid_map, robot_pose, z):\n",
    "    \"\"\"\n",
    "    Processes a new sensor observation to update the occupancy grid map.\n",
    "    \n",
    "    Parameters:\n",
    "    - grid_map: An object representing the occupancy grid map. It should contain:\n",
    "        - map.shape: Shape of the map grid to check boundary limits.\n",
    "        - resolution: Resolution of each cell in the grid map.\n",
    "        - log_odds: 2D numpy array of log-odds values for each cell.\n",
    "    - robot_pose: The robot's current pose, represented as a numpy array of shape (3, 1)\n",
    "      containing [x, y, theta].\n",
    "    - z: Sensor observations,  representing distances and angles of detected obstacles.\n",
    "\n",
    "    \"\"\"\n",
    "    z_endpoints = beams_endpoints(None, None, None)  \n",
    "    cells_to_update = get_cells_to_update(None, None, None, None)    \n",
    "    p_cells_occupied = inverse_beam_sensor_model(None, None, None, None)\n",
    "    update_log_odds(None, None, None, None)\n",
    "    update_probabilities(None)    \n",
    "\n",
    "    # Display control buttons and plot the updated map and robot state\n",
    "    create_and_display_buttons()\n",
    "    plot_state(robot_pose, z_endpoints, virtual_map, grid_map, cells_to_update)\n",
    "\n",
    "\n",
    "def move_robot(dx=0, dy=0, dtheta=0):\n",
    "    \"\"\"\n",
    "    Moves the robot by applying a specified translation and rotation, and processes the new observation.\n",
    "\n",
    "    Parameters:\n",
    "    - dx: Displacement along the x-axis.\n",
    "    - dy: Displacement along the y-axis.\n",
    "    - dtheta: Rotation angle to be applied (in radians).\n",
    "    \"\"\"\n",
    "    global robot_pose\n",
    "    u = np.vstack([None, None, None])  # Movement vector\n",
    "\n",
    "    # Update the robot pose with the new movement\n",
    "    robot_pose = tcomp(None, None)\n",
    "    \n",
    "    # Update the laser's pose and take a new observation\n",
    "    laser.set_pose(None)\n",
    "    z = laser.take_observation(None)\n",
    "    \n",
    "    # Process the new observation to update the map\n",
    "    process_new_observation(None, None, None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec008ae-79e3-4df2-8eec-ed47d5714210",
   "metadata": {},
   "source": [
    "Okay, it's time to stop working and have a bit of fun. **Execute the code below**, move the robot, and **build a map!** \n",
    "\n",
    "You should obtain something like this:\n",
    "\n",
    "<figure>\n",
    "  <img src=\"images/final_occupancy_grid_map_probabilities.jpg\" alt=\"\">\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be209c4f-1ce2-4c2b-979a-c5728766f398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize robot pose and robot map\n",
    "robot_pose = np.vstack([5, 4, np.pi / 4])  # [x, y, theta]\n",
    "grid_map = OccupancyGridMap(map_width, map_height, resolution)\n",
    "\n",
    "# Define an Output widget\n",
    "output = widgets.Output()\n",
    "\n",
    "#create_and_display_buttons()\n",
    "display(output)  # Display the output widget for plotting\n",
    "\n",
    "# Process first observation\n",
    "process_new_observation(grid_map, robot_pose, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc253c8e-d12c-43d6-8bef-34e9936651ef",
   "metadata": {},
   "source": [
    "Cool! We now have the final log odds and probability values! This is just one remaining thing to do to build the occupancy grid map... to decide if a cell is occupied or free according to their probabilities. For doing that we are going to use this simple rule:\n",
    "\n",
    "\n",
    "$$\n",
    "m_i = \n",
    "\\begin{cases} \n",
    "0 & \\text{if } P(m_i | z_{1:t}, x_{1:t}) > u_{\\text{th}} \\\\ \n",
    "1 & \\text{if } P(m_i | z_{1:t}, x_{1:t}) < l_{\\text{th}} \\\\ \n",
    "0.5 & \\text{Otherwise} \n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "where $u_{\\text{th}}$ and $l_{\\text{th}}$ are thresholds to consider if a cell is occupied or free according to its probability. \n",
    "\n",
    "The next cell do that, so **execute it** and enjoy with your result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0907e4-bc20-4a70-8bef-9295ba0fc7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define thresholds\n",
    "lower_threshold = 0.3  # Probability below this will be set to 0\n",
    "upper_threshold = 0.7 # Probability above this will be set to 1\n",
    "\n",
    "# Update the map based on thresholds\n",
    "grid_map.map = np.full_like(grid_map.probabilities, 0.5)\n",
    "grid_map.map[grid_map.probabilities < lower_threshold] = 1\n",
    "grid_map.map[grid_map.probabilities > upper_threshold] = 0\n",
    "\n",
    "# Assume grid_map.map is already defined with values 0, 0.5, and 1\n",
    "# Define a simple color map for the three values\n",
    "cmap = plt.cm.get_cmap('gray', 3)  # 'gray' with 3 discrete colors for 0, 0.5, and 1\n",
    "\n",
    "# Plot the occupancy grid map\n",
    "plt.imshow(grid_map.map, cmap=cmap, origin='lower', vmin=0, vmax=1)\n",
    "plt.title('Occupancy Grid Map')\n",
    "plt.xlabel('X (cells)')\n",
    "plt.ylabel('Y (cells)')\n",
    "\n",
    "# Add grid overlay\n",
    "plt.gca().set_xticks(np.arange(-0.5, grid_map.map.shape[1], 1), minor=True)\n",
    "plt.gca().set_yticks(np.arange(-0.5, grid_map.map.shape[0], 1), minor=True)\n",
    "plt.gca().grid(which='minor', color='black', linestyle='-', linewidth=0.1)\n",
    "\n",
    "# Add a simple legend to represent the three values\n",
    "labels = ['Unoccupied (0)', 'Unknown (0.5)', 'Occupied (1)']\n",
    "colors = [cmap(i) for i in range(3)]\n",
    "for color, label in zip(colors, labels):\n",
    "    plt.plot([], [], 's', color=color, label=label)\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9df3b5-0493-4f2d-8d89-9bb03d9307e6",
   "metadata": {},
   "source": [
    "<span style=\"color:blue\">Expected output</span>\n",
    "\n",
    "<figure>\n",
    "  <img src=\"images/final_occupancy_grid_map.jpg\" alt=\"\">\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ad880b-9144-44c0-b15d-2a3b1005d8af",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we covered the fundamental steps of building an Occupancy Grid Map (OGM), a popular technique for robotic navigation and environment mapping. Here’s a summary of what we learned:\n",
    "\n",
    "- **Concept of Occupancy Grid Maps:** We explored how OGMs divide the environment into a grid, where each cell holds a probability of being occupied or free, enabling robots to model their surroundings with uncertainty.\n",
    "- **Sensor Integration and Ray Tracing:** We used a 2D laser scanner to gather distance measurements. Ray tracing was used to identify which cells each laser beam intersects, providing information for occupancy updates.\n",
    "\n",
    "- **Probabilistic Updates with Log-Odds:** To handle noisy sensor data and maintain consistency, we applied log-odds to update the occupancy probabilities. This allowed for incremental updates as new observations were gathered.\n",
    "\n",
    "- **Complete Pipeline Implementation:** Combining all elements, we created a pipeline that:\n",
    "\n",
    "  - Processes sensor observations,\n",
    "  - Updates the grid map based on probabilities,\n",
    "  - Visualizes the map building state.\n",
    "\n",
    "With this notebook we have got a deeper understanding of how robots can map their surroundings and make decisions based on probabilistic data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d76dabb-4a8a-4d4d-85e1-4928d834094a",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">OPTIONAL</span>\n",
    "\n",
    "<span style=\"color:green\">\n",
    "<p>There are many aspects of the implementation that can be improved to do it more realistic. Some ideas:</p>\n",
    "<ul>\n",
    "    <li>Include time measurements in the code to detect bottlenecks and do it more efficient.</li>\n",
    "    <li>Consider that the localization is not given, so you have to compute it when the robot moves. You can use, for example, ICP.</li>\n",
    "    <li>There are different alternatives to do ray tracing, implement a different one. Some options appear in this paper: <a href=\"https://www.sciencedirect.com/science/article/pii/S0921889023000027\" target=\"_blank\">Object-wise comparison of LiDAR occupancy grid scan rendering methods</a>\n",
    "    <li>Implement moving obstacles (people, pets, etc.).</li>\n",
    "    <li>Laser related:\n",
    "    <ul>\n",
    "        <li>Test the efect of different real lasers (surf the internet to find them, e.g. Hokuyo, Sick) in the resulting map (different FOV, max range, resolution, error, etc.).</li>\n",
    "        <li>Implement additional sources of uncertainty in the laser measurements: random and max range.</li>\n",
    "        <li>Implement different surfaces in the map, so the sensor performance may vary (e.g., appearing large errors). For example, black surfaces absorb more infrarred rays, difficulting sensor operation.</li>\n",
    "        <li>Change the virtual map definition to an arbitrary input image, and implement a new laser simulator able to work with this new representation (e.g. ray tracing). </li>\n",
    "    </ul>\n",
    "    </li>    \n",
    "</ul>\n",
    "</span>\n",
    "\n",
    "<span style=\"color:green\">***END OF OPTIONAL PART***</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
